{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPx7d4BP/hpuDI2aIPuQbg+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jhlbxx/-/blob/master/Predicting_the_sentiment_of_IMDB_movie_records.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torchdata"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 504
        },
        "id": "LDM77y8ON47B",
        "outputId": "b17f93bb-c70d-4b3e-9403-f674828c9afb"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting torchdata\n",
            "  Downloading torchdata-0.5.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.6/4.6 MB\u001b[0m \u001b[31m39.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: torch==1.13.1 in /usr/local/lib/python3.8/dist-packages (from torchdata) (1.13.1+cu116)\n",
            "Collecting urllib3>=1.25\n",
            "  Downloading urllib3-1.26.14-py2.py3-none-any.whl (140 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m140.6/140.6 KB\u001b[0m \u001b[31m16.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting portalocker>=2.0.0\n",
            "  Downloading portalocker-2.7.0-py2.py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from torchdata) (2.25.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torch==1.13.1->torchdata) (4.5.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->torchdata) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->torchdata) (2022.12.7)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->torchdata) (4.0.0)\n",
            "Installing collected packages: urllib3, portalocker, torchdata\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 1.24.3\n",
            "    Uninstalling urllib3-1.24.3:\n",
            "      Successfully uninstalled urllib3-1.24.3\n",
            "Successfully installed portalocker-2.7.0 torchdata-0.5.1 urllib3-1.26.14\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "urllib3"
                ]
              }
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "TRGbip0RNkA8"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torchtext.datasets import IMDB\n",
        "train_dataset = IMDB(split='train')\n",
        "test_dataset = IMDB(split='test')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Step 1: create the datasets\n",
        "from torch.utils.data.dataset import random_split\n",
        "torch.manual_seed(1)\n",
        "train_dataset, valid_dataset = random_split(list(train_dataset),[20000,5000])"
      ],
      "metadata": {
        "id": "D-VLmGyXN_vV"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Step 2: find unique tokens (words)\n",
        "import re\n",
        "from collections import Counter, OrderedDict\n",
        "\n",
        "def tokenizer(text):\n",
        "  text = re.sub('<[^>]*>', '',text)\n",
        "  emoticons = re.findall('(?::\\;|=)(?:-)?(?:\\)|\\(|D|P)', text.lower())\n",
        "  text = re.sub('[\\W]+', ' ', text.lower()) + ' '.join(emoticons).replace('-','')\n",
        "  tokenized = text.split()\n",
        "  return tokenized"
      ],
      "metadata": {
        "id": "dP62gm_OPO15"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "token_counts = Counter()\n",
        "for label, line in train_dataset:\n",
        "  tokens = tokenizer(line)\n",
        "  token_counts.update(tokens)\n",
        "print('Vocab-size:', len(token_counts))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "agH_fyufT3Py",
        "outputId": "3abeed1c-0435-42ca-c3a8-1ad921d2c2ff"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vocab-size: 75953\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Step 3: encoding each unique token into integers\n",
        "from torchtext.vocab import vocab\n",
        "sorted_by_freq_tuples = sorted(token_counts.items(), key=lambda x: x[1], reverse=True)\n",
        "ordered_dict = OrderedDict(sorted_by_freq_tuples)\n",
        "vocab = vocab(ordered_dict)\n",
        "vocab.insert_token(\"<pad>\",0)\n",
        "vocab.insert_token(\"<unk>\",1)\n",
        "vocab.set_default_index(1)"
      ],
      "metadata": {
        "id": "iBS9C4v0UGh6"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print([vocab[token] for token in ['this','is','an','example']])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UxqmDtEJeBiH",
        "outputId": "e95e8b47-074a-4c5e-a3e3-e77529cd097c"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[11, 7, 35, 462]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Step 3-A: define the functions for transformation\n",
        "text_pipeline = lambda x: [vocab[token] for token in tokenizer(x)]\n",
        "label_pipeline = lambda x:1. if x=='pos' else 0."
      ],
      "metadata": {
        "id": "5g9wffnzfSbx"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn"
      ],
      "metadata": {
        "id": "ztn1DbAHiwOx"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Step 3-B: wrap the encode and transformation function\n",
        "def collate_batch(batch):\n",
        "  label_list, text_list, lengths = [],[],[]\n",
        "  for _label, _text in batch:\n",
        "    label_list.append(label_pipeline(_label))\n",
        "    processed_text = torch.tensor(text_pipeline(_text),dtype=torch.int64)\n",
        "    text_list.append(processed_text)\n",
        "    lengths.append(processed_text.size(0))\n",
        "  label_list = torch.tensor(label_list)\n",
        "  lengths = torch.tensor(lengths)\n",
        "  padded_text_list = nn.utils.rnn.pad_sequence(text_list, batch_first=True)\n",
        "  return padded_text_list, label_list, lengths"
      ],
      "metadata": {
        "id": "R9p1_GQbhIoN"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6tu2IsNDi0mI"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}